\documentclass[12pt, reqno]{amsart}

%%%%%%%%%%%%%%%%%%%%%  MY STUFF %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\makeatletter
%\g@addto@macro{\endabstract}{\@setabstract}
%\makeatother


%\usepackage{epsfig}
\usepackage{graphics, stackrel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{amsfonts}
\usepackage{natbib}
\usepackage{enumitem}
%font
%\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage{fontspec} 
\usepackage[xcharter]{newtxmath}
%\setmainfont{XCharter}
%\usepackage{mathpazo}
%\usepackage{tgpagella}

%subfloats / figures
\usepackage{caption}
\usepackage{subcaption}

% For pandas latex tables

\usepackage{fancyvrb}
\usepackage[dvipsnames,svgnames,table]{xcolor}
\usepackage{mdwlist}

\usepackage[citecolor=blue, colorlinks=true, linkcolor=blue]{hyperref}


% lists
\usepackage{enumitem}
\setlist[enumerate]{itemsep=2pt,topsep=3pt}
\setlist[itemize]{itemsep=2pt,topsep=3pt}
\setlist[enumerate,1]{label=(\roman*)}

\usepackage{mathrsfs}  % caligraphic
%\usepackage{stix} 
\usepackage{bbm}
\usepackage{bm}        % bold symbols


%% page layout
\usepackage[left=1.25in, right=1.25in, top=1.0in, bottom=1.15in, includehead, includefoot]{geometry}

% nice inequalities
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}

% inner product
\providecommand{\inner}[1]{\left\langle{#1}\right\rangle}
\providecommand{\innerp}[1]{\left\langle{#1}\right\rangle_\pi}


\usepackage[ruled, linesnumbered]{algorithm2e}

%extra spacing
\renewcommand{\baselinestretch}{1.32}


%horizonal line
\newcommand{\HRule}{\rule{\linewidth}{0.3mm}}

% skip a line between paragraphs, no indentation
\setlength{\parskip}{1.5ex plus0.5ex minus0.5ex}
\setlength{\parindent}{0pt}

% footnote without a maker (blfootnote)
\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}

\DeclareMathOperator{\Span}{span}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\DeclareMathOperator{\cl}{cl}
\DeclareMathOperator{\Int}{int}
%\DeclareMathOperator{\overset{\circ}}{int}
\DeclareMathOperator{\Prob}{Prob}
\DeclareMathOperator{\determinant}{det}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\graph}{graph}

% mics short cuts and symbols
\newcommand{\st}{\ensuremath{\ \mathrm{s.t.}\ }}
\newcommand{\setntn}[2]{ \{ #1 : #2 \} }
\newcommand{\fore}{\therefore \quad}
\newcommand{\preqsd}{\preceq_{sd} }
\newcommand{\toas}{\stackrel {\textrm{ \scriptsize{a.s.} }} {\to} }
\newcommand{\tod}{\stackrel { d } {\to} }
\newcommand{\tou}{\stackrel { u } {\to} }
\newcommand{\toweak}{\stackrel { w } {\to} }
\newcommand{\topr}{\stackrel { p } {\to} }
\newcommand{\disteq}{\stackrel { \mathscr D } {=} }
\newcommand{\eqdist}{\stackrel {\textrm{ \scriptsize{d} }} {=} }
\newcommand{\iidsim}{\stackrel {\textrm{ {\sc iid }}} {\sim} }
\newcommand{\1}{\mathbbm 1}
\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}
\newcommand{\dee}{\,{\rm d}}
\newcommand{\og}{{\mathbbm G}}
\newcommand{\ctimes}{\! \times \!}
\newcommand{\sint}{{\textstyle\int}}

\newcommand{\given}{\, | \,}
\newcommand{\A}{\forall}

% d for integrals
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand*\e{\mathrm{e}}


% Special symbols and shortcuts
\newcommand{\bmeta}{\bm{\eta}}
\newcommand{\bmxi}{\bm{\xi}}

\newcommand{\infot}{\fF_t}

\newcommand{\pspace}{\mathscr{P}(\mathsf{X})}
\newcommand{\cspace}{\mathscr{C}(\mathsf{X})}

%\renewcommand{\times}{\! \times \!}

\newcommand{\aA}{\mathscr A}
\newcommand{\cC}{\mathscr C}
\newcommand{\sS}{\mathcal S}
\newcommand{\bB}{\mathscr B}
\newcommand{\oO}{\mathcal O}
\newcommand{\gG}{\mathcal G}
\newcommand{\hH}{\mathcal H}
\newcommand{\kK}{\mathcal K}
\newcommand{\iI}{\mathcal I}
\newcommand{\eE}{\mathcal E}
\newcommand{\fF}{\mathscr F}
\newcommand{\qQ}{\mathcal Q}
\newcommand{\tT}{\mathcal T}
\newcommand{\xX}{\mathcal X}
\newcommand{\yY}{\mathcal Y}
\newcommand{\rR}{\mathcal R}
\newcommand{\zZ}{\mathcal Z}
\newcommand{\wW}{\mathcal W}
\newcommand{\uU}{\mathcal U}
\newcommand{\lL}{\mathcal L}

\newcommand{\mM}{\mathcal M}
\newcommand{\dD}{\mathcal D}

\newcommand{\pP}{\mathring P}

\newcommand{\vV}{\mathcal V}

\newcommand{\Bsf}{\mathsf B}
\newcommand{\Hsf}{\mathsf H}
\newcommand{\Vsf}{\mathsf V}

\newcommand{\BB}{\mathbbm B}
\newcommand{\DD}{\mathbbm D}
\newcommand{\RR}{\mathbbm R}
\newcommand{\CC}{\mathbbm C}
\newcommand{\QQ}{\mathbbm Q}
\newcommand{\NN}{\mathbbm N}
\newcommand{\GG}{\mathbbm G}
\newcommand{\UU}{\mathbbm U}
\newcommand{\TT}{\mathbbm T}
\newcommand{\YY}{\mathbbm Y}
\newcommand{\ZZ}{\mathbbm Z}
\newcommand{\HH}{\mathbbm H}
\newcommand{\MM}{\mathbbm M}
\newcommand{\PP}{\mathbbm P}
\newcommand{\EE}{\mathbbm E}


\newcommand{\bH}{\mathbf H}
\newcommand{\bT}{\mathbf T}

\newcommand{\var}{\mathbbm V}

\newcommand{\Xsf}{\mathsf X}
\newcommand{\Isf}{\mathsf I}
\newcommand{\Wsf}{\mathsf W}

\renewcommand{\phi}{\varphi}
\renewcommand{\epsilon}{\varepsilon}

\newcommand{\bP}{\mathbf P}
\newcommand{\bQ}{\mathbf Q}
\newcommand{\bE}{\mathbf E}
\newcommand{\bM}{\mathbf M}
\newcommand{\bX}{\mathbf X}
\newcommand{\bY}{\mathbf Y}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}


\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{axiom}{Axiom}[section]
\newtheorem{example}{Example}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{notation}{Notation}[section]
\newtheorem{assumption}{Assumption}[section]
\newtheorem{condition}{Condition}[section]


%\DeclareTextFontCommand{\emph}{\bfseries}

%%%%%%%%%%%%%%%%%% end my preamble %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\begin{document}


\title{Quasi-hyperbolic discounting note}


\maketitle


The aim is to apply ADP methods to quasi-hyperbolic discounting (QHD).  

\section{Fully Rational QHD}

Fully rational means that at time zero you choose a stationary policy that
maximizes lifetime value and keep it forever.

Lifetime value of policy $\sigma$ starting from $t=0$ is 
%
\begin{equation*}
    w_\sigma(x) 
    \coloneq
    r_\sigma(x) + \beta \EE_x 
        \sum_{t \geq 1} \delta^t r_\sigma(X_t)
\end{equation*}
%
Pointwise this is
%
\begin{equation*}
    w_\sigma = r_\sigma + \beta P_\sigma \sum_{t \geq 1} (\delta P_\sigma)^t r
\end{equation*}
%
Suppose for now that states and actions are finite, so $w_\sigma$ takes values
in $V \coloneq \RR^\Xsf$.

We generalize to allow state-dependent discounting, taking $B_\sigma$ and
$D_\sigma$ to be
positive linear operators over $V$ and writing
%
\begin{equation}\label{eq:vdef}
    w_\sigma = r_\sigma + B_\sigma \sum_{t \geq 1} D_\sigma^t \, r_\sigma
\end{equation}
%
To maximize $w_\sigma$ using ADP theory we can
%
\begin{enumerate}
    \item write $w_\sigma$ as the fixed point of an operator $S_\sigma$ and
    \item show that $(V, \{S_\sigma\})$ is a globally stable ADP.
\end{enumerate}
%
Let's start by finding $S_\sigma$.  For now we drop the subscript $\sigma$ To
simplify notation. Rearranging \eqref{eq:vdef} gives
%
\begin{equation*}
    w 
    = r + B D r + B \sum_{t \geq 2} D^t r
    = r + B D r + B D \sum_{t \geq 1} D^t r
\end{equation*}
%
Assuming that $B$ is invertible and using \eqref{eq:vdef} again gives
%
\begin{equation*}
    w 
    = r + B D r + B D B^{-1} (w - r)
\end{equation*}
%
For example, in the case where $B= \beta$, we have
%
\begin{equation*}
    w 
    = r + \beta D r + D (w - r)
    = r - (1 - \beta) D r + D \, w
\end{equation*}
%
For this case, putting the subscript $\sigma$ back in, we write
%
\begin{equation*}
    S_\sigma \, w = r_\sigma - (1 - \beta) D_\sigma r_\sigma + D_\sigma \, w
\end{equation*}
%
If, say, $\sup_\sigma \rho(D_\sigma) < 1$, then we have a globally stable ADP
with value function $v^*$ and at least one optimal policy $\sigma^*$.  The usual
optimality results apply:

\begin{enumerate}
    \item Bellman's principle of optimality holds.
    \item VFI, HPI, OPI converge, etc.
\end{enumerate}


\section{QHD with Limited Self-Control}

In HL and BRW, the perspective is as follows: 

\begin{itemize}
    \item There are separate ``selves'' at each point in time $t$.  
    \item The $t=1$ self chooses a policy $\sigma$ and receives rewards
        according to
        %
        \begin{equation}\label{eq:os}
            v_\sigma 
            = \sum_{t \geq 0} (\delta P_\sigma)^t r_\sigma
            = \sum_{t \geq 0} D^t r_\sigma
        \end{equation}
        %
    \item The $t=0$ self takes $v_\sigma$ in \eqref{eq:os} as given and chooses a policy
        $\tau$ to solve
        %
        \begin{equation*}
            \tau(x) \in \argmax_{a \in \Gamma(x)}
            \left\{
                r(x, a) + \beta \sum_{x'} v_\sigma(x') P(x, a, x')
            \right\}
        \end{equation*}
        %
\end{itemize}

We have a stationary Markov Nash equilibrium (SMNE) when $\tau = \sigma$.

We can write this more abstractly as follows:  Let
%
\begin{itemize}
    \item $T_\sigma \, v = r_\sigma + D_\sigma \, v$ 
    \item $\hat T_\sigma \, v = r_\sigma + B_\sigma \, v$ and $\hat T = \bigvee_\sigma
        \hat T_\sigma$ 
\end{itemize}
%
Let $\tau = M \sigma$ be defined by choosing $v_\sigma$ as the fixed point of
$T_\sigma$ and then $\tau$ such that $\hat T v_\sigma = \hat T_\tau v_\sigma$.
We seek a fixed point of $M$.

Questions:
%
\begin{enumerate}
    \item The policy $\tau$ is not necessarily optimal for the self at $t=1$.
        Why would the self at $t=1$ accept it?
    \item Why does the self at $t=1$ have different preferences to the self at
        $t=0$?  If they are all copies of the same ``self,'' then each faces an
        infinite horizon and has the same lifetime objective \eqref{eq:vdef}.
        In particular, the self at $t=1$ should choose $\sigma$ to maximize
        \eqref{eq:vdef} rather than \eqref{eq:os}.
    \item What justification is there for focusing only on \emph{stationary} Markov Nash equilibria?  
    \item Are there any stability results for SMNE, showing that boundedly
        rational agents naturally converge to this behavior.
    \item Given that there are no uniqueness results for SMNE, how can we use
        this for quantitative work?
\end{enumerate}



%\bibliographystyle{ecta}
%\bibliography{localbib}

\end{document}

% Local Variables:
% TeX-engine: xetex
% End:
